61:

  personal
  kursmoment
  laborationer
  tentamen
  litteratur
  upplägg
  datorer
  marknad för processorer
  datorns delar
  output device
  input device
  datorns insida
  minne processorn
  ic tillverkning
  intel
  moores lag - trender
  dator
  användarprogram, OS och hårdvara
  program
  ALU - arithmetic logic unit
  register
  sekventiell logik
  register och primärminne
  variabler och minne
  minne
  byte eller wordadresserat minne
  hur sätts byte ihop till word?
  kontrollenhet
  exekvering av en instruktion
  kontrollenhet
  cpu tid
  execkveringstid
  prestanda [tenta E1]

62:

  program
  exekvering av en instruktion
  kontrollenhet
  exekveringstid
  prestanda
  markininstruktioner
  aritmetiska operationer
  adressering
  varför olika sätt att adressera? [tenta E4]
  adressering: avvägningar
  hoppinstruktioner
  hoppinstruktion
    ovilkkorliga hopp
    villkorliga hopp
  subrutiner och funktioner
  stack
  stack för subrutiner och funktioner
  register för subrutiner och funktioner
  återhopp och parameteröverföring
  in- och utmatning
  minnessmappad och isolerad I/O
  exempel på minnesmappad I/O
  maskininstruktione
  instruktionsformat
  antal addresser i instruktion
  semantiskt glapp
  utvärdering av applikationsprogram
  RSIC - Reduced Instruction Set Computers
  CISC - Complex Instruction Set Computers

63:

  program
  semantiskt gap
  datatyper [tenta E2]
  tilldelningssatser
  aritmetiska operationer
  beräkningar
  bithantering
  villkor
  villkorsuttryck
  loopar
  funktioner
  pekare
  pekare till funktioner
  variablers synlighet
  include
  dator
  OS - inledning
  Unix
  Linux
  vad gör ett OS?
  program
  hur går det till att byta program?
  kontextbyte
  processkontrollblock
    datastruktur inneh. inf. som beh. för att kunna hantera givet prog.
      innh. typiskt: PID,reg.värden,PC.,stackp.
  processhantering
  process modell
  schemaläggare
  minneshantering
    relocation
    memory protection
    sharing
  hantera hårdvaruresurser
  systemanrop
    avbrott genereras av klocka (HW.)
    avbrott gen. av systemanrop (SW.)

  polling/avbrott
    polling - konti. avl. av input
    avbrott - proc. gör annat fram till avb.
  filsystem (inode)
    12x direct pointers
  vad gör ett OS?
    processhantering
    minneshantering
    filsystem
    drivrutiner
    nätvärk
    säkerhet
    I/O

64:

  filsystem - inode
  minnets komponenter
  programexekvering
  minnet från processorns sida
  minneshantering
  minnet
    primärminne
    sekundärminne (HDD)
      lågnivå - seiktorer och tracks
      partionering - logiska diskar
      högnivåformatering - vilket OS ska anv.?
      schemaläggare
        shortest-seek time from head
        elevator algo. - move bach and forth
        one-way elevator - move in one direction
      fragmentering:
        extern - de olika "blocken" ligger med mellanrum, nytt block
                 kanske inte får plats.
        intern - datan fyller inte ut blocket helt, oanvända bytes
  design av minnessystem
  minneshirarki [tenta F2]
  cacheminne [tenta R4] [tenta E3]
    temporal lokalitet - lokalitet i tiden
    rumslokalitet - sannor. större att närliggande addr. för nuvar. anv.
    utnyttja lokalitet
      lagra allt på hårddisk.
      kopiera "recentlu accessed (and nearby) items från HDD -> prim. minne.
      kopiera "recentlu accessed (and nearby) items från prim. minne -> cache
  ersättningsalgoritmer
  skrivstrategier
  prestanda
  prestanda - multilevel cache
  paging
  inode
  demand paging
  virtuellt minne
    nästa
  translation look-aside buffer [tenta R2]
    nästa

65:

  design av minnen
    vill ha: stort minnes med samma klockf. som processorn.

  minneshirarki
    cpu reg. : 8-32st (a 32 bitar -> 32-128 bytes) : få ns / 0-1 klc.
    on chip cache (L1) : 32-128 kbyte : ~10 ns / 3 klc.
    off chip cache (L2) : 128 kbyte - 12 Mbytes : 10tals ns / 10 klc.
    main mem. (RAM) : 256 Mbytes - 4 Gbytes : ~100 ns / 100 klc.
    hdd : 1 Gbyte - 1 Tbyte : 10-tals msek, 10 000 000 klc.

  cacheminne [tenta E3]
    direktmapping [tenta E3]
    associativemapping [tenta E3]
    2-vägs set associative

  jämför cacheminnen
    direktmapping (tänk hashmap)
    fully associativemapping (tänk lista)
    2-vägs set-associa. (tänk hashmap med listor)

  ersättningsalgoritmer
    impl. i hårdv. prest. viktigt
    slupmässigt
    least recently used (LRU)
    first in first out (FIFO)
    least freq. used (LFU)


  skrivstrategier
    write-through: skriv direkt till cache vid uppda.
    write-through with buffers: buffra -> skriv perio.
    write (copy)-back: uppdatera när en cache-rad byts
    ofta dirty bit

  antal cachenivåer
    prim <-> L2 <-> L1 <-> reg (cpu)

  separat instruktion/data cache
    primär <-I-> instruktioner <-I-> register (cpu)
    primär <-D-> data <-D-> register (cpu)

  prestanda [tenta R4]
    påverkas av cycler för prog.exek. (ink. cache hit tid)
    I-cache (inst.) = I-miss * miss-penalty
    D-cache (data.) = load-store * miss-rate * miss-penalty
    Ta ideal hast. (CPI) addera I- o D-cache -> actual CPI

  prestanda - multilevel cache
    Ef. CPI = CPI + fa(L1)*pen(L2) + miss(glob-prim)*pen(L1)

  cache coherency
    flera cach-kopior av samma minne skall vara lika

  cache coherency - problem
    missmatch mellan processer som delar samma adressrymd

  virtuellt minne
    varje prog. får priv. addr.rymd.
    färre ramar än sidor.
    demand paging - långsammare ju fler sidor.

  translation Look-Aside buffer (TLB)
    anv. cache för sidtabell -> snabbare än att läsa prim. minne.

66:

  Närliggande allokering
    minnet blir fragmenterat

  Virtuellt minne
    anv. prim.minne (RAM) som cache för sekund. minne (HDD).
    antal platser = frames
    data från program = page
    program -dela-> pages -sätt-> tabell
    tabell -ref-> till plats i prim.minne

  programexekvering
    fetch-execute
      fetch: hämta instruktion
        * hämta instr. på addr.
        * flytta instruktion till CPU.
        * avkoda instruktion.
      execute: kör instruktionen
        * utf inst. - hämta data på addr.
        * utf inst. - spara data på addr2.

  pipelining [tenta R4]
    köra inst. i typ parallell.
    FI / DI / CO / FO / EI / WO

  strukturella hazards [tenta R3]
    2st inst. vill acc. samma resurser ex. läsa minne.
    minska med mer res. ex. sep. data- o inst-cache.

  data hazards
    inst. I2 ber. av I1. utan pipel. I1 färdig före I2.
    med pipel. ej säkert. I2 kan bli klar innan I1 så I2 mst. vänta
    -> data hazard.

    kan minska med forward/bypass ALUn -> MUX.

  kontroll hazards
    kontroll hazard uppkommer på grund av hopp/branch inst.

  minska penalties vid hopp
    hopp påv. pipeline pres.

  delayed branching [tenta E4]
    flyttar inst. till branch delay slot. Exekv. innan branch.

  instruction fetch unit och instruktionskö
    flesta proc. har fetch units som hämtar inst. innan de behövs.
    lagras i inst-kö. Kan känna igen hopp och gen. hoppadr.

  branch prediction
    gissa taken/not taken.
    gissar o hämtar inst
      a) rätt -> forst.
      b) fel -> hämta rätt inst.

  speculative exeuction [tenta R3]
    exek. inst. innan processorn vet om det är rätt.
    static branch prediction
      ingen hist. ex, hoppet tar aldrig/alltid/ber. riktning (fram/bak).
    dynamic branch prediction
      anv. historik. en bit, dvs, spara förra, gör samma.
    tvåbitas prediktering
      gissning bas. på senaste 2 fallen.
    branch history
      används för att lagra res. och vart ett hopp går anv. för gissning.

  delayed load problem
    det som loadas blir inte tillängligt förrens nästa klockcykel
    -> res. i NOP.
    delayed load: exekvera alltid inst. efter load, se till att var i
    load inte anv. dir. ef. load.

67:

  Fetch execute [tenta R1]
    med pipelining kan fetch och execute överlappa -> sparar tid.

  Pipelining
    6-steg:
      Fetch Instruction - FI
      Decode Instruction - DI
      Calculate Operand address - CO
      Fetch Operand - FO
      Execute instuction - EI
      Write operand - WO

    problem (hazards):
      strukturella / data / kontroll

  Parallellberäkning
    Sigle core CPUer för lite -> multicore / gemensamma resurs /
    bussstruktur.

  Klassificering av datorarkitetkturer [tenta R5]
    SISD - Single-instruction-single-datastream
      en ström inst. en ström data
      Minne -IS-> CPU(kontrollenh. -> ber.enh) -DS-> Minne
    SIMD - Singel-instruction-multiple-datastream
      en ström inst. flera data
      Minne -IS-> CPU(kontrollenh. -> (ber.enh[1,2,3..]) -DS[1,2,3]-> Minne
    MISD
    MIMD
  Multicore och muticomputer

  Prestanda på parallella arkitekturer

    Amdalhs lag

      f=exek. sekve.
      1-f=exek. paralellt.

      T_s = exekv.tid sekven.
      T_p = exekv.tid parall.

      Exekveringstid: T_p = f*T_s+(1-f)*T_s/p
      Speedup; S = T_s/T_p
      Efficiency: E = S/p

  Superscalar architecture

    paralella enheter kan exek. sammtidigt, ex 2xint + 1xfloat
    typer: skalär: heltal, flyttal.
           icke-skallär: matris, vektor.

  Instruktionsfönster

    De instruktioner som processen kan välja vid viss tidpunkt.
    Stort -> effektivt.

    problem
      * svårt att hämta inst. med hög hast.
      * konf. i pipeline (branch, strukural, data)

  Problem parallell exekvering

    Resource konf.

    Kontroll konf.

    Datakonf.

      True data dependency / data konflitk/hazard [tenta R5]
        En instruktion måste vänt a på res. från annan inst.

      Output dependency
        Två instruktioner skriver till samma plats, ändring i ord. ->
        annat värde.

      Anti dependency
        En instruktion använder ett värde som kan ändras under tiden
        av annan instruktion.

  Register renaming
    Använda andra register för att undvika serialliseing

  Parallell exekvering
    in-order issue / in order comple.
      intruktionerna kommer ut samma som in.
    in-order issue / out of order comple.
      intruktionerna kommer ut annorlunda än in.

  konflikthantering

    in-order issue with in-order completion
      bara bara hantera true data dependency

    in-order issue with out-of-order completion
      (...)

    out-of-order issue with out-of-order completion
      beh. hantera true data, output och anti-dependency.

  VLIW

    kompilatorn hanterar detetktering av parallellism.

  kontextbyte

    A running - context switch (A -> PCBA && PCBB -> B) - B running
    context switch (B -> PCBB  && PCBA -> A) - A running.

  processer och trådar

    process består av flera trådar där tråd är sekventiell kod som kan
    exek. tillsammans med andra trådar.

    trådarna delar samma data och stack.

    hårdvarustöd:
      * programräknare och register per tråd.
      * instruktionshämtning (fetch) på tråd basis.
      * kontextbyte (byte av tråd)

    multithreading scalar

        större chans att kunna exek. instruktioner parallellt.  vid ex.
        blockering pga minnesacc. kan instr. från annan tråd exek.

        interleaved kör en instruktion från varje blocked kör klart (till
        avbrott?) för varje process.

      supercalar

        Hårdvaran detekterar om det går att parallellisera.

        A superscalar CPU architecture implements a form of parallelism
        called instruction-level parallelism within a single processor. It
        therefore allows faster CPU throughput than would otherwise be
        possible at a given clock rate. A superscalar processor executes more
        than one instruction during a clock cycle by simultaneously
        dispatching multiple instructions to different functional units on
        the processor. Each functional unit is not a separate CPU core but an
        execution resource within a single CPU such as an arithmetic logic
        unit, a bit shifter, or a multiplier.

        In Flynn's taxonomy, a single-core superscalar processor is
        classified as an SISD processor (Single Instruction stream, Single
        Data stream), though many superscalar processors support short vector
        operations and so could be classified as SIMD (Single Instruction
        stream, Multiple Data streams).  A multi-core superscalar processor
        is classified as an MIMD processor (Multiple Instruction streams,
        Multiple Data streams).

        While a superscalar CPU is typically also pipelined, pipelining and
        superscalar architecture are considered different performance
        enhancement techniques.

        The superscalar technique is traditionally associated with several
        identifying characteristics (within a given CPU core):

        Instructions are issued from a sequential instruction stream CPU
        hardware dynamically checks for data dependencies between
        instructions at run time (versus software checking at compile time)
        The CPU processes multiple instructions per clock cycle

        Interleaved multithreading Run a section/line on A then a
        section/line on B etc.  Blocked multitherading Distribute a process
        over the processor until it's done and change.  Simultaneous
        multitherading (SMT) Run all different threads simultaneously.
